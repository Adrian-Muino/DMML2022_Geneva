|  <img width="600" height="400" src="https://user-images.githubusercontent.com/101266297/209135507-21954fa6-4a09-4331-ad82-4f2f50c8ec88.png">      | <img width="400" height="200" src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Logo_Universit%C3%A9_de_Lausanne.svg/300px-Logo_Universit%C3%A9_de_Lausanne.svg.png"> |
| ----------- | ----------- |

# DMML2022_Geneva
By Adrian Muino & David Hornung aka Gimli-coding

##Brief description of the project : 

The project was to find the best machine learning model in order to classify french text in order of difficulty (A1,A2,B1,B2,C1,C2)

The utility of such project is to help identify the difficulty level of French sentences in order to improve someone’s skills. As it is important to read texts in when you trying to learn a new language, these texts have to be at the reader’s language level. However, it is difficult to find texts that are close to someone’s knowledge level (A1 to C2).

For this reason, we have been asked to build a model for English speakers that predicts the difficulty of a French written text. This can be then used, e.g., in a recommendation system, to recommend texts, e.g, recent news articles that are appropriate for someone’s language level. If someone is at A1 French level, it is inappropriate to present a text at B2 level, as he or she won’t be able to understand it. Ideally, a text should have many known words and may have a few words that are unknown so that the person can improve.


# Table of Contents

1. [Mandatory Models]().

2. [Improved Models](https://github.com/Adrian-Muino/DMML2022_Geneva/blob/main/Code/2.DMML_2022_Geneva_Improved_Models.ipynb).

3. [Linear regression using embeding](https://github.com/Adrian-Muino/DMML2022_Geneva/blob/main/Code/3.DMML_2022_Geneva_Embeding_Model.ipynb).

4. [Bert & Tensor Model](https://github.com/Adrian-Muino/DMML2022_Geneva/blob/main/Code/4.DMML_2022_Geneva_Bert%26Tensor_Model.ipynb)
 
</br>
<p align="center">
<img width="1000" src="https://user-images.githubusercontent.com/114933900/208974347-0e640dd3-8c55-4e01-9b8b-67a3b3737591.png">
<p>

  </br>

# Methodology

We decided to separate our work in 4 different colab from the simpliest model to the most complicated one.
</br>
##Mandatory models
  </br>
</br>
In the first colab "Models ask by the faculty" we do no data cleaning and keep the sentence has they are. We tokenize our word and train the following models:
</br></br></br>
<p align="center">
<img width="800" src="https://user-images.githubusercontent.com/101266297/209134864-7231e754-2b73-4832-9b92-86694b135633.png">
<p>
</br></br></br>
<p align="center">
<img width="400" src="https://fontmeme.com/permalink/221219/f4054e7e06c7a18ca481271166811921.png">
<p>
</br>
</br>
<p align="center">
<img width="1000" src="https://user-images.githubusercontent.com/114933900/208957680-09efa1be-0c5f-475c-856c-386085b7ceb2.png">
<p>
</br>


</br>
<p align="center">
<img width="400" src="https://fontmeme.com/permalink/221219/99485c5ec53a29415b16a94c2100bc5c.png">
<p>
</br>
</br>

<p align="center">
<img width="400" src="https://user-images.githubusercontent.com/114933900/208947363-6b57c2a0-20ff-40f9-bbf0-47139540f95c.png">
<p>

 </br>
</br>
<p align="center">
<img width="400" src="https://fontmeme.com/permalink/221219/89919f5ad9759f663241eca5f028525c.png">
<p>
</br>

## Summary of the results table : (TO BE COMPLETED)


## Link to the explainatory video : (TO BE COMPLETED)


