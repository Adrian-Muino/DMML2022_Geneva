{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHweZ/Hn1IYPf1lmFzpbHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adrian-Muino/DMML2022_Geneva/blob/main/Mandatory_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation\n",
        "!pip install sentence-transformers\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!python -m spacy link fr_core_news_sm fr\n",
        "!pip install tensorflow_hub\n",
        "!pip install tensorflow_text\n",
        "! pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "#read in your Kaggle credentials from Google Drive\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# download the dataset from the competition page\n",
        "! kaggle competitions download -c detecting-french-texts-difficulty-level-2022\n",
        "!unzip detecting-french-texts-difficulty-level-2022.zip"
      ],
      "metadata": {
        "id": "spHBXAEyG3hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY8yg5YtGjN8"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeClassifier, Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from google.colab import drive\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading in the data via the Kaggle API & mount your Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "df = df_train = pd.read_csv(\"training_data.csv\")"
      ],
      "metadata": {
        "id": "jf11ZsVKHMDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "Uj7fHC0VHsMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base line calculation\n",
        "difficulty_A1_count = df.loc[df[\"difficulty\"] == \"A1\"].shape[0]\n",
        "difficulty_A2_count = df.loc[df[\"difficulty\"] == \"A2\"].shape[0]\n",
        "difficulty_B1_count = df.loc[df[\"difficulty\"] == \"B1\"].shape[0]\n",
        "difficulty_B2_count = df.loc[df[\"difficulty\"] == \"B2\"].shape[0]\n",
        "difficulty_C1_count = df.loc[df[\"difficulty\"] == \"C1\"].shape[0]\n",
        "difficulty_C2_count = df.loc[df[\"difficulty\"] == \"C2\"].shape[0]\n",
        "baserate = max(difficulty_A1_count, difficulty_A2_count,difficulty_B1_count,difficulty_B2_count,difficulty_C1_count,difficulty_C2_count)/(df[\"difficulty\"].shape[0])\n",
        "print(\"Baserate = \", baserate)"
      ],
      "metadata": {
        "id": "K1yjrKkdHrra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "xtOTivyrH6YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector_spacy = TfidfVectorizer(tokenizer=spacy_tokenizer_sm)"
      ],
      "metadata": {
        "id": "rXXCLWprH9br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"sentence\"] # the features we want to analyze\n",
        "y = df[\"difficulty\"] # the labels we want to test against\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "zvYuLGglJAwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "LR_spacy_model= LogisticRegression(solver = \"lbfgs\", multi_class = 'multinomial')\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "LR_spacy_pipe = Pipeline([('vectorizer', tfidf_vector_spacy), ('classifier', LR_spacy_model)])\n",
        "\n",
        "# Fit model on training set\n",
        "LR_spacy_pipe.fit(X_train, y_train)\n",
        "\n",
        "LR_spacy_pred = LR_spacy_pipe.predict(X_test)\n",
        "\n",
        "LR_spacy_report = evaluate(y_test, LR_spacy_pred)\n",
        "\n",
        "# Storing the model performance results in a DF called reports\n",
        "reports['Logistic Regression Spacy'] = LR_spacy_report\n",
        "\n",
        "LR_spacy_report"
      ],
      "metadata": {
        "id": "76wUpPBbJD_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test, LR_spacy_pred, LR_spacy_pipe)"
      ],
      "metadata": {
        "id": "9-hLeLB9JIYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "badly_predicted = pd.DataFrame({'sentence':X_test[LR_spacy_pred != y_test],\n",
        "              'predicted':LR_spacy_pred[LR_spacy_pred != y_test],\n",
        "              'true':y_test[LR_spacy_pred != y_test]})\n",
        "\n",
        "\n",
        "for i, row in badly_predicted.sample(3).iterrows():\n",
        "    print(row.sentence)\n",
        "    print(f\"Predicted: {row.predicted}\")\n",
        "    print(f\"Actual: {row.true}\")"
      ],
      "metadata": {
        "id": "Cd7i99pCJJqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-nearest neighbors algorithm"
      ],
      "metadata": {
        "id": "YXohCuY5JNx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifier\n",
        "knn_spacy_model = KNeighborsClassifier()\n",
        "Nknn = list(range(1, 100))\n",
        "param_grid = dict(n_neighbors=Nknn)\n",
        "\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "\n",
        "knn_spacy_grid = GridSearchCV(knn_spacy_model, param_grid, cv=5, scoring='accuracy', return_train_score=False,verbose=1)\n",
        "\n",
        "knn_spacy_pipe = Pipeline([('vectorizer',  tfidf_vector_spacy), ('classifier', knn_spacy_grid)])\n",
        "# Fit model on training set\n",
        "knn_spacy_pipe.fit(X_train, y_train)\n",
        "\n",
        "best_param_knn_spacy = knn_spacy_grid .best_params_.get('n_neighbors')\n",
        "print(knn_spacy_grid .best_params_)"
      ],
      "metadata": {
        "id": "t8z2-md6JVbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_spacy_classifier = KNeighborsClassifier(n_neighbors=best_param_knn_spacy)\n",
        "# Create pipeline\n",
        "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "KNN_spacy_pipe = Pipeline([('vectorizer', tfidf_vector_spacy), ('classifier', knn_spacy_classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "KNN_spacy_pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "KNN_spacy_pred = KNN_spacy_pipe.predict(X_test)\n",
        "\n",
        "KNN_spacy_pred_report = evaluate(y_test, KNN_spacy_pred)\n",
        "\n",
        "# Storing the model performance results in a DF called reports\n",
        "reports['KNN Spacy'] = KNN_spacy_pred_report\n",
        "\n",
        "KNN_spacy_pred_report"
      ],
      "metadata": {
        "id": "dlXTWduKJbfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test, KNN_spacy_pred, KNN_spacy_pipe)"
      ],
      "metadata": {
        "id": "7PV1x4oKJd5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision tree"
      ],
      "metadata": {
        "id": "Hgv_4WAVJhiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for fitting trees of various depths on the training data using cross-validation\n",
        "def run_cross_validation_on_trees(X, y, tree_depths, cv=5, scoring='accuracy'):\n",
        "    cv_scores_list = []\n",
        "    cv_scores_std = []\n",
        "    cv_scores_mean = []\n",
        "    accuracy_scores = []\n",
        "    for depth in tree_depths:\n",
        "        tree_model = DecisionTreeClassifier(max_depth=depth)\n",
        "        cv_scores = cross_val_score(tree_model, X_train, y_train, cv=cv, scoring=scoring)\n",
        "        cv_scores_list.append(cv_scores)\n",
        "        cv_scores_mean.append(cv_scores.mean())\n",
        "        cv_scores_std.append(cv_scores.std())\n",
        "        accuracy_scores.append(TREEpipe.fit(X_train, y_train).score(X_test, y_test))\n",
        "    cv_scores_mean = np.array(cv_scores_mean)\n",
        "    cv_scores_std = np.array(cv_scores_std)\n",
        "    accuracy_scores = np.array(accuracy_scores)\n",
        "    return cv_scores_mean, cv_scores_std, accuracy_scores\n",
        "\n",
        "def plot_cross_validation_on_trees(depths, cv_scores_mean, cv_scores_std, accuracy_scores, title):\n",
        "    fig, ax = plt.subplots(1,1, figsize=(15,5))\n",
        "    ax.plot(depths, cv_scores_mean, '-o', label='mean cross-validation accuracy', alpha=0.9)\n",
        "    ax.fill_between(depths, cv_scores_mean-2*cv_scores_std, cv_scores_mean+2*cv_scores_std, alpha=0.2)\n",
        "    ylim = plt.ylim()\n",
        "    ax.plot(depths, accuracy_scores, '-*', label='train accuracy', alpha=0.9)\n",
        "    ax.set_title(title, fontsize=16)\n",
        "    ax.set_xlabel('Tree depth', fontsize=14)\n",
        "    ax.set_ylabel('Accuracy', fontsize=14)\n",
        "    ax.set_ylim(ylim)\n",
        "    ax.set_xticks(depths)\n",
        "    ax.legend()\n",
        "\n",
        "numberoftry = range(1,26)\n",
        "sm_mean, sm_std, sm_scores = run_cross_validation_on_trees(X_train, y_train, numberoftry)\n",
        "\n",
        "# plotting accuracy\n",
        "plot_cross_validation_on_trees(numberoftry, sm_mean, sm_std, sm_scores, \n",
        "                               'Accuracy per decision on training data')"
      ],
      "metadata": {
        "id": "2ygnNfTfJosK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_spacy_model = DecisionTreeClassifier()\n",
        "\n",
        "tree_spacy_pipe = Pipeline([('vectorizer', tfidf_vector_spacy),\n",
        "                 ('classifier', tree_spacy_model)])\n",
        "\n",
        "\n",
        "tree_spacy_pipe.fit(X_train, y_train)\n",
        "\n",
        "tree_spacy_pred = tree_spacy_pipe.predict(X_test)\n",
        "\n",
        "tree_spacy_report = evaluate(y_test, tree_spacy_pred)\n",
        "\n",
        "# Store model performance results\n",
        "reports['Decision Tree Spacy'] = tree_spacy_report\n",
        "\n",
        "tree_spacy_report"
      ],
      "metadata": {
        "id": "ORGFT3ZeJktS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_test, tree_spacy_pred, tree_spacy_pipe)"
      ],
      "metadata": {
        "id": "6SlTMJ1UJmsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}